{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# United States Immigration Data Analysis\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project’s objective was to establish an ETL pipeline for I94 immigration, earth surface temperatures, airport codes, and city demographic datasets to create an analytics data warehouse for US immigration trends.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The scope of this project is to create an analytics data warehouse to track U.S. Immigration Data. \n",
    "This analytics solution will help answer questions about trends in immigration. \n",
    "For example: \n",
    "- \"Does the average temperature of a city make a city more appealing for immigrants?\" or \n",
    "- \"What is the most popular month for immigrating to the United States?\" \n",
    "\n",
    "The tools utilized for this project include **Apache Spark and Amazon S3**. Spark will be used to read and process the data and S3 will store the fact and dimension tables created with a Snowflake architecture. \n",
    "\n",
    "#### Describe and Gather Data \n",
    "For this project, I will being using three datasets: I94 Immirgration Data, World Temperature Data, and U.S. Cities Demographic Data. For descriptions and exploration of these datasets, please refer to the cells below. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### I94 Immigration Data\n",
    "---\n",
    "This SAS dataset includes data pertaining to the I-94 Vistor Arrivals Program. The National Travel and Tourism Office work with the U.S. Department of Homeland Security to release this data. It contains information about each person that enters the United States from another Country. \n",
    "\n",
    "\n",
    "For more information about this dataset please refer to the [National Travel and Tourism Office website](https://www.trade.gov/national-travel-and-tourism-office).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "df_i94 = pd.read_csv(\"immigration_data_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### World Temperature Data\n",
    "---\n",
    "This dataset comes from Kaggle. Stored in a CVS file, this file contains data about Global Land Temperatures by city. \n",
    "\n",
    "For more information about this dataset please refer to this [Kaggle Dataset](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "df_temp = pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### U.S. Cities Demographic Data\n",
    "---\n",
    "This dataset, also stored as a CSV file, comes from opendatasoft and utilizes Census Bureau data from 2015.\n",
    "\n",
    "For more information about this dataset please refer to the [opendatasoft Dataset](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "df_demog = pd.read_csv(\"city_demo_data/us-cities-demographics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City;State;Median Age;Male Population;Female Population;Total Population;Number of Veterans;Foreign-born;Average Household Size;State Code;Race;Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring;Maryland;33.8;40601;41862;82463;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy;Massachusetts;41.0;44129;49500;93629;41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover;Alabama;38.5;38040;46799;84839;4819;822...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga;California;34.5;88127;87105;1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark;New Jersey;34.6;138040;143873;281913;58...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  City;State;Median Age;Male Population;Female Population;Total Population;Number of Veterans;Foreign-born;Average Household Size;State Code;Race;Count\n",
       "0  Silver Spring;Maryland;33.8;40601;41862;82463;...                                                                                                   \n",
       "1  Quincy;Massachusetts;41.0;44129;49500;93629;41...                                                                                                   \n",
       "2  Hoover;Alabama;38.5;38040;46799;84839;4819;822...                                                                                                   \n",
       "3  Rancho Cucamonga;California;34.5;88127;87105;1...                                                                                                   \n",
       "4  Newark;New Jersey;34.6;138040;143873;281913;58...                                                                                                   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demog.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---\n",
    "#### I94 Immigration Data\n",
    "A few fields in this dataset have many null values. These fields have been excluded from the dataframe before they are written to the parquet file in S3. Other fields we excluded that did not fit to desired model. \n",
    "\n",
    "\n",
    "**Fields excluded from the dataset:**\n",
    " - i94mode\n",
    " - count\n",
    " - dtadfile\n",
    " - entdepa\n",
    " - entdepd\n",
    " - entdepu\n",
    " - matflag\n",
    " - biryear\n",
    " - occup\n",
    "\n",
    "All fields are defined as strings except arrdate and depdate. \n",
    "\n",
    "Arrdate and depdate have been converted to datetime from SAS date type but are stored as strings.\n",
    "\n",
    "\n",
    "Duplicate values have been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---\n",
    "#### I94 SAS Labels Descriptions\n",
    "Data from the file has been manually cleaned using Excel and saved into four csv files, located in the i94_sas_label_data directory, containing **key/value** matches for:\n",
    " - [City(Port)](i94_sas_label_data/i94_cities.csv) \n",
    " - [State](i94_sas_label_data/i94_states.csv) \n",
    " - [Visa](i94_sas_label_data/i94_visas.csv) \n",
    " - [County](i94_sas_label_data/i94_countries.csv)\n",
    "\n",
    "\n",
    "All fields are defined as strings. \n",
    "\n",
    "\n",
    "Duplicate values have been removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---\n",
    "#### World Temperature Data\n",
    "To clean and wrangle this dataset, the following steps have been taken:\n",
    "1. Limit the dataset to only include data from the U.S.\n",
    "2. Convert dt string into date format and extract the year\n",
    "3. Limit the dataset to include only data from the latest year in the dataset (2013)\n",
    "4. Convert AverageTemperature to a double value for aggregation\n",
    "5. Calculate the average temperature and convert the temperature from Celsius to Fahrenheit\n",
    "\n",
    "\n",
    "To see more detailed steps taken to clean this data set, please refer to *clean_temperature_data* in [elt.py](elt.py).\n",
    "\n",
    "\n",
    "**Fields excluded from this dataset are as follows:**\n",
    " - AverageTemperatureUncertainty\n",
    " - Latitude\n",
    " - Longitude\n",
    "\n",
    "All fields are defined as strings, expect for Average Temperature that has been converted to a double for aggregation and dt that has been converted in year with format 'YYYY'. \n",
    "\n",
    "\n",
    "Duplicate values have been removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---\n",
    "#### U.S. Cities Demographics Data\n",
    "Some fields have been excluded from this dataset to prevent redundancy and to preserve the data model.\n",
    "\n",
    "\n",
    "**Fields excluded from the dataset:**\n",
    " - Number of Veterans\n",
    " - Race\n",
    " - Count\n",
    "\n",
    "All fields are defined as strings. \n",
    "\n",
    "\n",
    "Duplicate values have been removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "![Conceptual Data Model](Immigration_Data_Model.jpg)\n",
    "For this data warehouse, I chose to implement a snowflake model containing one Fact and five Dimension tables. This model was chosen to provide a structured, partially normalized approach to the data. The snowflake schema allows for children to have one or more parent tables and that coincided well with the chosen data sets. Snowflake schemas also allow one to many relationships, which was crutial for relationships between dimension tables. My goal was to partially normalize the data to make querying more intuitive, while still providing the bulk of the data in the fact table to foster faster performance.   \n",
    "\n",
    "\n",
    "**fact_immigration_i94**\n",
    "\n",
    "This fact table contains data from the I94 Immigration Dataset. The primary key is cic_id. It was chosen as the primary key because it was already included with the dataset and is unique to each record.\n",
    "\n",
    "This table has seven foreign keys that refer to the dimension tables. The foreign keys primarily act as a reference to lookup codes stored in the fact table to prevent data redundancy.\n",
    "\n",
    "---\n",
    "**dim_county**\n",
    "\n",
    "This dimension table contains data from I94 SAS Label Descriptions file and was manually processed into a csv file. The primary key is **country_cd**. It was chosen to be able to lookup country codes from the immigration table and get their associated name.\n",
    "\n",
    "---\n",
    "**dim_visa**\n",
    "\n",
    "This dimension table contains data from I94 SAS Label Descriptions file and was manually processed into a csv file. The primary key is **visa_cd**. It was chosen to be able to lookup visa type codes from the immigration table and get their associated description.\n",
    "\n",
    "---\n",
    "**dim_state**\n",
    "\n",
    "This dimension table contains data from I94 SAS Label Descriptions file and was manually processed into a csv file. The primary key is **state_cd**. It was chosen to be able to lookup visa type codes from the immigration table and get their associated name.\n",
    "\n",
    "---\n",
    "**dim_city**\n",
    "\n",
    "This dimension table contains data from I94 SAS Label Descriptions file and was manually processed into a csv file. The primary key is a composite of **city_cd** and **city_name**. It was chosen to be able to lookup city codes from the immigration table and get their associated name as well as serve as a point of reference for cities in dim_city_demographics.\n",
    "\n",
    "---\n",
    "**dim_city_demographics**\n",
    "\n",
    "This dimension table contains data from I94 SAS Label Descriptions file and was manually processed into a csv file.The primary key is a composite of **city** and **state_cd**. State_cd is a foreign key from dim_state. This table makes my design a Snowflake schema because it has multiple parents (City and State) and allows for a many to one relationship with the dim_state table. This was chosen to be able to lookup city and state codes from the associated dimension tables.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "1. Create a Spark session to aid the ELT processes\n",
    "2. Process I94 SAS Label Descriptions data\n",
    " - Read, load the data in dataframes, and finally write the data to parquet files stored in S3 for dim_country, dim_city, dim_state, and dim_visa tables\n",
    "3. Process City Demographics Data\n",
    " - Read City Demographics and World Temperature data, clean World Temperature data, join dataframes, and write the data to a parquet file stored in S3 for dim_city_demographics table\n",
    "4. Process Immigration Data\n",
    "  - Read, load the data in dataframe, and finally write the data to a parquet file stored in S3 for fact_immigration_i94 table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read countries data\n",
      "countries data has been written\n",
      "read cities data\n",
      "cities data has been written\n",
      "read states data\n",
      "states data has been written\n",
      "read visas data\n",
      "visas data has been written\n",
      "read demographics data\n",
      "read temperature data\n",
      "temperature data is being cleaned\n",
      "temperature data has been cleaned\n",
      "demographics data has been written\n",
      "read immigration data\n",
      "immigration data has been written\n",
      "Starting quality checks\n",
      "Empty check passed. Table: dim_country_table is not empty. There are 289 rows.\n",
      "Unique check passed. Table: dim_country_table has 289 unique rows.\n",
      "Quality checks complete\n",
      "Starting quality checks\n",
      "Empty check passed. Table: dim_city_table is not empty. There are 603 rows.\n",
      "Unique check passed. Table: dim_city_table has 603 unique rows.\n",
      "Quality checks complete\n",
      "Starting quality checks\n",
      "Empty check passed. Table: dim_state_table is not empty. There are 55 rows.\n",
      "Unique check passed. Table: dim_state_table has 55 unique rows.\n",
      "Quality checks complete\n",
      "Starting quality checks\n",
      "Empty check passed. Table: dim_visa_table is not empty. There are 3 rows.\n",
      "Unique check passed. Table: dim_visa_table has 3 unique rows.\n",
      "Quality checks complete\n",
      "Starting quality checks\n",
      "Empty check passed. Table: dim_city_demographics_table is not empty. There are 596 rows.\n",
      "Unique check passed. Table: dim_city_demographics_table has 596 unique rows.\n",
      "Quality checks complete\n",
      "Starting quality checks\n",
      "Empty check passed. Table: fact_immigration_94_table is not empty. There are 1000 rows.\n",
      "Unique check passed. Table: fact_immigration_94_table has 1000 unique rows.\n",
      "Quality checks complete\n"
     ]
    }
   ],
   "source": [
    "%run elt.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Two quality checks were performed on the tables in this data model:\n",
    "1. Empty check: Verify that there are no empty rows in the table\n",
    "2. Unique check: Verify that every row is unique in the table\n",
    "\n",
    "Please refer to [quality_checks.py](quality_checks.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "The data dictionary is located in this [file](data_dictionary.md), please navigate there to view it.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Tools and Technology\n",
    "\n",
    " - AWS S3: Data can be stored securely, affordably, and can easily be transfer to BI and Analytics Applications\n",
    " - Apache Spark (Pyspark): Can be used to read and transform big data, which is needed for the Immigration dataset\n",
    " - EMR Big Data Cluster (optional): Can be used to speed up the data processing and loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Updates\n",
    " - Immigration data should be updated every month because that is the cadence of the raw dataset as well.\n",
    " - City Demographics data can be updated annually because that's how frequently it is collected by the government.\n",
    "     - World Temperature data can be updated annually as well, if the data is available.\n",
    " - Data from SAS Label Data (Country, Visa, State, City) data does not need to be updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Scenarios\n",
    " - The data was increased by 100x:\n",
    "     - An AWS EMR Cluster could be implemented to process the influx of data. Spark alone cannot handle that volume of data.\n",
    " - The data populates a dashboard that must be updated on a daily basis by 7am every:\n",
    "     - The elt process can be rewritten using Apache Airflow. Airflow provides an intuitive way to schedule DAG runs that would easily solve this.\n",
    " - The database needed to be accessed by 100+ people\n",
    "     - In order for 100+ people to access this data warehouse, it would need to be moved to Amazon Redshift - or another similar platform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Sample Query\n",
    "\n",
    "The parquet files were copied into AWS Athena for sample querying. The sample query and results are as follows:\n",
    "\n",
    "Note: the sample size Immigration Data was used for this query, actual results may be larger\n",
    "\n",
    "Query:\n",
    "\n",
    "SELECT cic_id, i94_year, i94_month, i94_city_cd, city_name, i94_state_cd, arr_date, dep_date,  ins_num, male_pop, female_pop, total_pop, avg_temperature, median_age, avg_hh_size\n",
    "FROM fact_immigration_i94 i INNER JOIN dim_city c ON i.i94_city_cd = c.city_cd\n",
    "LEFT OUTER JOIN dim_city_demographics cd ON c.city_name = cd.city \n",
    "AND i.i94_state_cd = cd.state_cd\n",
    "\n",
    "Results:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query_results = pd.read_csv(\"query_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>i94_year</th>\n",
       "      <th>i94_month</th>\n",
       "      <th>i94_city_cd</th>\n",
       "      <th>city_name</th>\n",
       "      <th>i94_state_cd</th>\n",
       "      <th>arr_date</th>\n",
       "      <th>dep_date</th>\n",
       "      <th>ins_num</th>\n",
       "      <th>male_pop</th>\n",
       "      <th>female_pop</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>median_age</th>\n",
       "      <th>avg_hh_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4753503.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1396100.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5951265.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AGA</td>\n",
       "      <td>Agana</td>\n",
       "      <td>GU</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>3663.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4340220.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>Miami</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4800385.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>MI</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>2016-06-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1782990.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>2016-04-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>155381.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-09-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5512209.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439752.0</td>\n",
       "      <td>425064.0</td>\n",
       "      <td>864816.0</td>\n",
       "      <td>61.2206</td>\n",
       "      <td>38.3</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>87211.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>GA</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>494733.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-05-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439752.0</td>\n",
       "      <td>425064.0</td>\n",
       "      <td>864816.0</td>\n",
       "      <td>61.2206</td>\n",
       "      <td>38.3</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3542252.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5206668.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2167869.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>Boston</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4711317.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1376054.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2859612.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>Miami</td>\n",
       "      <td>MS</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>834035.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>Newark/Teterboro</td>\n",
       "      <td>PA</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2187824.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5081809.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MI</td>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4267184.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1858517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>2016-07-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439752.0</td>\n",
       "      <td>425064.0</td>\n",
       "      <td>864816.0</td>\n",
       "      <td>61.2206</td>\n",
       "      <td>38.3</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1232357.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439752.0</td>\n",
       "      <td>425064.0</td>\n",
       "      <td>864816.0</td>\n",
       "      <td>61.2206</td>\n",
       "      <td>38.3</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4042798.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130940.0</td>\n",
       "      <td>139977.0</td>\n",
       "      <td>270917.0</td>\n",
       "      <td>74.7874</td>\n",
       "      <td>33.1</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>442884.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439752.0</td>\n",
       "      <td>425064.0</td>\n",
       "      <td>864816.0</td>\n",
       "      <td>61.2206</td>\n",
       "      <td>38.3</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5472156.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>2016-05-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639019.0</td>\n",
       "      <td>661063.0</td>\n",
       "      <td>1300082.0</td>\n",
       "      <td>68.8114</td>\n",
       "      <td>32.6</td>\n",
       "      <td>2.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5258247.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4300706.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>Miami</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>2016-05-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5760102.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439752.0</td>\n",
       "      <td>425064.0</td>\n",
       "      <td>864816.0</td>\n",
       "      <td>61.2206</td>\n",
       "      <td>38.3</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3119472.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>2016-05-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5979347.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AGA</td>\n",
       "      <td>Agana</td>\n",
       "      <td>GU</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>3943.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4268549.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>2016-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341137.0</td>\n",
       "      <td>341408.0</td>\n",
       "      <td>682545.0</td>\n",
       "      <td>52.1704</td>\n",
       "      <td>34.1</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>247003.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5285085.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>2016-05-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1339481.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3097076.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1401034.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5293311.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4693164.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439752.0</td>\n",
       "      <td>425064.0</td>\n",
       "      <td>864816.0</td>\n",
       "      <td>61.2206</td>\n",
       "      <td>38.3</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3686758.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-20</td>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3507607.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-19</td>\n",
       "      <td>2016-05-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1163269.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1422091.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Washington</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1636545.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>2016-04-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439752.0</td>\n",
       "      <td>425064.0</td>\n",
       "      <td>864816.0</td>\n",
       "      <td>61.2206</td>\n",
       "      <td>38.3</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3442997.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-18</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130940.0</td>\n",
       "      <td>139977.0</td>\n",
       "      <td>270917.0</td>\n",
       "      <td>74.7874</td>\n",
       "      <td>33.1</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1347695.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>LA</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>2016-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4718538.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4522231.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PHO</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>DC</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>2016-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>17786.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NE</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5724253.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>674661.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4081698.0</td>\n",
       "      <td>4468707.0</td>\n",
       "      <td>8550405.0</td>\n",
       "      <td>53.8950</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cic_id  i94_year  i94_month i94_city_cd         city_name i94_state_cd  \\\n",
       "0   4753503.0    2016.0        4.0         HHW          Honolulu           HI   \n",
       "1   1396100.0    2016.0        4.0         HHW          Honolulu           HI   \n",
       "2   5951265.0    2016.0        4.0         AGA             Agana           GU   \n",
       "3   4340220.0    2016.0        4.0         MIA             Miami          NaN   \n",
       "4   4800385.0    2016.0        4.0         ATL           Atlanta           MI   \n",
       "5   1782990.0    2016.0        4.0         NYC          New York           NY   \n",
       "6    155381.0    2016.0        4.0         ATL           Atlanta           CA   \n",
       "7   5512209.0    2016.0        4.0         SFR     San Francisco           CA   \n",
       "8     87211.0    2016.0        4.0         CHI           Chicago           GA   \n",
       "9    494733.0    2016.0        4.0         SFR     San Francisco           CA   \n",
       "10  3542252.0    2016.0        4.0         HHW          Honolulu           HI   \n",
       "11  5206668.0    2016.0        4.0         NYC          New York           NY   \n",
       "12  2167869.0    2016.0        4.0         BOS            Boston           NY   \n",
       "13  4711317.0    2016.0        4.0         NYC          New York           NY   \n",
       "14  1376054.0    2016.0        4.0         NYC          New York           NY   \n",
       "15  2859612.0    2016.0        4.0         MIA             Miami           MS   \n",
       "16   834035.0    2016.0        4.0         NEW  Newark/Teterboro           PA   \n",
       "17  2187824.0    2016.0        4.0         HHW          Honolulu           HI   \n",
       "18  5081809.0    2016.0        4.0         BOS            Boston           MI   \n",
       "19  4267184.0    2016.0        4.0         NYC          New York           NY   \n",
       "20  1858517.0    2016.0        4.0         SFR     San Francisco           CA   \n",
       "21  1232357.0    2016.0        4.0         SFR     San Francisco           CA   \n",
       "22  4042798.0    2016.0        4.0         ORL           Orlando           FL   \n",
       "23   442884.0    2016.0        4.0         SFR     San Francisco           CA   \n",
       "24  5472156.0    2016.0        4.0         DAL            Dallas           TX   \n",
       "25  5258247.0    2016.0        4.0         HHW          Honolulu           HI   \n",
       "26  4300706.0    2016.0        4.0         MIA             Miami          NaN   \n",
       "27  5760102.0    2016.0        4.0         SFR     San Francisco           CA   \n",
       "28  3119472.0    2016.0        4.0         NYC          New York           NY   \n",
       "29  5979347.0    2016.0        4.0         AGA             Agana           GU   \n",
       "30  4268549.0    2016.0        4.0         DEN            Denver           CO   \n",
       "31   247003.0    2016.0        4.0         SEA           Seattle          NaN   \n",
       "32  5285085.0    2016.0        4.0         NYC          New York           NY   \n",
       "33  1339481.0    2016.0        4.0         NYC          New York           NY   \n",
       "34  3097076.0    2016.0        4.0         NYC          New York           NY   \n",
       "35  1401034.0    2016.0        4.0         NYC          New York           NY   \n",
       "36  5293311.0    2016.0        4.0         NYC          New York           NY   \n",
       "37  4693164.0    2016.0        4.0         SFR     San Francisco           CA   \n",
       "38  3686758.0    2016.0        4.0         NYC          New York           NY   \n",
       "39  3507607.0    2016.0        4.0         NYC          New York           NY   \n",
       "40  1163269.0    2016.0        4.0         NYC          New York           NY   \n",
       "41  1422091.0    2016.0        4.0         WAS        Washington           CA   \n",
       "42  1636545.0    2016.0        4.0         SFR     San Francisco           CA   \n",
       "43  3442997.0    2016.0        4.0         ORL           Orlando           FL   \n",
       "44  1347695.0    2016.0        4.0         CHI           Chicago           LA   \n",
       "45  4718538.0    2016.0        4.0         HHW          Honolulu           HI   \n",
       "46  4522231.0    2016.0        4.0         PHO           Phoenix           DC   \n",
       "47    17786.0    2016.0        4.0         NYC          New York           NE   \n",
       "48  5724253.0    2016.0        4.0         HHW          Honolulu           HI   \n",
       "49   674661.0    2016.0        4.0         NYC          New York           NY   \n",
       "\n",
       "      arr_date    dep_date  ins_num   male_pop  female_pop  total_pop  \\\n",
       "0   2016-04-25  2016-04-27      NaN        NaN         NaN        NaN   \n",
       "1   2016-04-08  2016-04-12      NaN        NaN         NaN        NaN   \n",
       "2   2016-04-03  2016-04-05   3663.0        NaN         NaN        NaN   \n",
       "3   2016-04-23  2016-04-24      NaN        NaN         NaN        NaN   \n",
       "4   2016-04-25  2016-06-06      NaN        NaN         NaN        NaN   \n",
       "5   2016-04-10  2016-04-18      NaN  4081698.0   4468707.0  8550405.0   \n",
       "6   2016-04-01  2016-09-06      NaN        NaN         NaN        NaN   \n",
       "7   2016-04-29  2016-05-07      NaN   439752.0    425064.0   864816.0   \n",
       "8   2016-04-01  2016-04-11      NaN        NaN         NaN        NaN   \n",
       "9   2016-04-03  2016-05-15      NaN   439752.0    425064.0   864816.0   \n",
       "10  2016-04-19  2016-04-23      NaN        NaN         NaN        NaN   \n",
       "11  2016-04-28  2016-05-04      NaN  4081698.0   4468707.0  8550405.0   \n",
       "12  2016-04-12  2016-04-16      NaN        NaN         NaN        NaN   \n",
       "13  2016-04-25  2016-05-04      NaN  4081698.0   4468707.0  8550405.0   \n",
       "14  2016-04-08  2016-04-12      NaN  4081698.0   4468707.0  8550405.0   \n",
       "15  2016-04-15  2016-04-21      NaN        NaN         NaN        NaN   \n",
       "16  2016-04-05  2016-04-09      NaN        NaN         NaN        NaN   \n",
       "17  2016-04-12  2016-04-15      NaN        NaN         NaN        NaN   \n",
       "18  2016-04-27  2016-05-08      NaN        NaN         NaN        NaN   \n",
       "19  2016-04-23  2016-05-12      NaN  4081698.0   4468707.0  8550405.0   \n",
       "20  2016-04-10  2016-07-06      NaN   439752.0    425064.0   864816.0   \n",
       "21  2016-04-07  2016-04-24      NaN   439752.0    425064.0   864816.0   \n",
       "22  2016-04-22  2016-05-14      NaN   130940.0    139977.0   270917.0   \n",
       "23  2016-04-03  2016-04-07      NaN   439752.0    425064.0   864816.0   \n",
       "24  2016-04-29  2016-05-04      NaN   639019.0    661063.0  1300082.0   \n",
       "25  2016-04-28  2016-05-02      NaN        NaN         NaN        NaN   \n",
       "26  2016-04-23  2016-05-10      NaN        NaN         NaN        NaN   \n",
       "27  2016-04-30  2016-05-22      NaN   439752.0    425064.0   864816.0   \n",
       "28  2016-04-16  2016-05-13      NaN  4081698.0   4468707.0  8550405.0   \n",
       "29  2016-04-08  2016-04-11   3943.0        NaN         NaN        NaN   \n",
       "30  2016-04-23  2016-05-06      NaN   341137.0    341408.0   682545.0   \n",
       "31  2016-04-02  2016-04-16      NaN        NaN         NaN        NaN   \n",
       "32  2016-04-28  2016-05-13      NaN  4081698.0   4468707.0  8550405.0   \n",
       "33  2016-04-07  2016-05-02      NaN  4081698.0   4468707.0  8550405.0   \n",
       "34  2016-04-17  2016-04-23      NaN  4081698.0   4468707.0  8550405.0   \n",
       "35  2016-04-08         NaN      NaN  4081698.0   4468707.0  8550405.0   \n",
       "36  2016-04-28  2016-05-09      NaN  4081698.0   4468707.0  8550405.0   \n",
       "37  2016-04-25  2016-04-30      NaN   439752.0    425064.0   864816.0   \n",
       "38  2016-04-20  2016-05-09      NaN  4081698.0   4468707.0  8550405.0   \n",
       "39  2016-04-19  2016-05-03      NaN  4081698.0   4468707.0  8550405.0   \n",
       "40  2016-04-07  2016-04-11      NaN  4081698.0   4468707.0  8550405.0   \n",
       "41  2016-04-08  2016-05-12      NaN        NaN         NaN        NaN   \n",
       "42  2016-04-09  2016-04-17      NaN   439752.0    425064.0   864816.0   \n",
       "43  2016-04-18  2016-04-23      NaN   130940.0    139977.0   270917.0   \n",
       "44  2016-04-08  2016-04-14      NaN        NaN         NaN        NaN   \n",
       "45  2016-04-25  2016-04-30      NaN        NaN         NaN        NaN   \n",
       "46  2016-04-24  2016-05-06      NaN        NaN         NaN        NaN   \n",
       "47  2016-04-01  2016-04-12      NaN        NaN         NaN        NaN   \n",
       "48  2016-04-30  2016-05-07      NaN        NaN         NaN        NaN   \n",
       "49  2016-04-04  2016-04-08      NaN  4081698.0   4468707.0  8550405.0   \n",
       "\n",
       "    avg_temperature  median_age  avg_hh_size  \n",
       "0               NaN         NaN          NaN  \n",
       "1               NaN         NaN          NaN  \n",
       "2               NaN         NaN          NaN  \n",
       "3               NaN         NaN          NaN  \n",
       "4               NaN         NaN          NaN  \n",
       "5           53.8950        36.0         2.68  \n",
       "6               NaN         NaN          NaN  \n",
       "7           61.2206        38.3         2.37  \n",
       "8               NaN         NaN          NaN  \n",
       "9           61.2206        38.3         2.37  \n",
       "10              NaN         NaN          NaN  \n",
       "11          53.8950        36.0         2.68  \n",
       "12              NaN         NaN          NaN  \n",
       "13          53.8950        36.0         2.68  \n",
       "14          53.8950        36.0         2.68  \n",
       "15              NaN         NaN          NaN  \n",
       "16              NaN         NaN          NaN  \n",
       "17              NaN         NaN          NaN  \n",
       "18              NaN         NaN          NaN  \n",
       "19          53.8950        36.0         2.68  \n",
       "20          61.2206        38.3         2.37  \n",
       "21          61.2206        38.3         2.37  \n",
       "22          74.7874        33.1         2.42  \n",
       "23          61.2206        38.3         2.37  \n",
       "24          68.8114        32.6         2.59  \n",
       "25              NaN         NaN          NaN  \n",
       "26              NaN         NaN          NaN  \n",
       "27          61.2206        38.3         2.37  \n",
       "28          53.8950        36.0         2.68  \n",
       "29              NaN         NaN          NaN  \n",
       "30          52.1704        34.1         2.33  \n",
       "31              NaN         NaN          NaN  \n",
       "32          53.8950        36.0         2.68  \n",
       "33          53.8950        36.0         2.68  \n",
       "34          53.8950        36.0         2.68  \n",
       "35          53.8950        36.0         2.68  \n",
       "36          53.8950        36.0         2.68  \n",
       "37          61.2206        38.3         2.37  \n",
       "38          53.8950        36.0         2.68  \n",
       "39          53.8950        36.0         2.68  \n",
       "40          53.8950        36.0         2.68  \n",
       "41              NaN         NaN          NaN  \n",
       "42          61.2206        38.3         2.37  \n",
       "43          74.7874        33.1         2.42  \n",
       "44              NaN         NaN          NaN  \n",
       "45              NaN         NaN          NaN  \n",
       "46              NaN         NaN          NaN  \n",
       "47              NaN         NaN          NaN  \n",
       "48              NaN         NaN          NaN  \n",
       "49          53.8950        36.0         2.68  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "query_results.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
